<!doctype html><html><head><title>AIT DSAI | Research | Explainable AI</title><meta name=viewport content="width=device-width,initial-scale=1"></head><body><nav class=sidebar-nav><a class=sidebar-nav-item href=/ title>Home</a>
<a class=sidebar-nav-item href=/about title>About</a>
<a class=sidebar-nav-item href=/research title>Research</a>
<a class=sidebar-nav-item href=/topics title>Topics</a>
<a class=sidebar-nav-item href=/projects title>Projects</a>
<a class=sidebar-nav-item href=/team title>Team</a>
<a class=sidebar-nav-item href=/contact title>Contact</a></nav><main><h1 id=explainable-artificial-intelligence>Explainable Artificial Intelligence</h1><p>Explainable AI, or better said, interpretable Machine Learning supports us in understanding the decisions made by our complex models, when and why the model might fail or succeed, and how we can improve our modelâ€™s performance by having gained more insight into its learning structure and the input data. Here at AIT, we incorporate explainability in our AI systems to improve the performance and detect biases in the data (e.g., XAI helps to detect gender biases in NLP models). This information develops and advances trust and fairness in deploying ML-models in the industry and provides ML-practitioners a guideline on the need for further research on transparent algorithms.</p><h1 id=reference-projects>Reference Projects</h1><h1 id=contact>Contact</h1></main></body></html>